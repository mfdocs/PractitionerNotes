<html>This document describes the process which can be followed to upgrade an older version HCM to 2020.05. The validated older versions of HCM are 2018.11, 2019.02, and 2019.05. Usually, the upgrade process includes upgrading the HCM to each individual incremental of available version, and cannot be upgraded directly to the latest available version. This would mean upgrading HCM 2018.11 to 2020.05 includes upgrading to 2019.02, 2019.05, 2019.08, 2019.11.<br>
<br>
The side-by-side upgrade (parallel instance-based) includes setting up a new version of the HCM 2020.05 version to which the data, configurations, and customizations would be copied to and thereby bring up the new version of HCM in another instance. The old version of HCM can be later decommissioned once the new version is LIVE.
<h2>Pre-requisites</h2>
The important requirement for side-by-side upgrade would be to have new servers, resources for bringing up the new HCM version. It is recommended that the resources and configurations should be the same as the older version of HCM.&nbsp;<br>
<br>
There can be a change in deployment architecture on the new HCM version, this would allow to make an adjustment to the HCM environment. For example, if you were using single master in the old version of HCM, you can deploy 2020.05 as multi-master.
<h3>NFS requirements</h3>
The new HCM instance would need its own NFS repository different from the old HCM version, the old NFS can be decommissioned after the upgrade.

<h3>Database requirements</h3>
In this upgrade, all the HCM databases of the older version are reused, the CDF IDM database is created new. So while installing the new version of HCM, you should create a new database for the CDF IDM which you would continue to use. For the HCM databases, you can use the internal Postgres or create temp databases since you will reconfigure the HCM to point to HCM databases of the older version during the upgrade process.&nbsp;<br>
It is recommended to clone the HCM databases to use with the new HCM version. This way you could still run the older version of HCM until you have the upgrade process completed and validated.
<h3>Virtual IP and Load Balancer configurations</h3>
When the older version of HCM is using a Virtual IP (VIP), we cannot use the same VIP with new HCM version deployment, the new HCM 2020.05 installation will use a new VIP. You have to change the VIP of the HCM 2020.05 to use the existing VIP (from the older version) unless the DNS can be reconfigured to use the same FQDN for new VIP, this is further described in later part of this document.<br>
<br>
When the older version HCM is using an external Load Balancer, then you can deploy the new version of HCM using the temporary load balancer and then reconfigure the external hostname in HCM after the upgrade to use the old Load Balancer. You must also change the load balancer configurations to use the new HCM instances.
<h2>Upgrade Procedure</h2>
The upgrade process assumes that the new HCM 2020.05 is deployed and is accessible. The databases are cloned and is available on to a database server.

<h3>Expose the database port in older version HCM (Only in case of internal Postgres)</h3>
You can skip this step if you are not using internal Postgres for the CDF IDM database.<br>
If you are using the internal Postgres database for the CDF IDM database, then you need to expose the Postgres port on that server. This is required to migrate the IDM database to 2020.05.
<h4>Single node Postgres Service</h4>
Steps to expose ITOM Postgres port outside of kubernetes cluster

<ol>
	<li>Modifiy pg_hba.conf in &lt;db-single-vol&gt;/baseinfra-1.0/postgresql95/ folder. Add below line to the file<br>
	&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;host &nbsp; &nbsp;all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.0.0.0/0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; md5</li>
	<li>Add below port mapping to the postgres yaml (&lt;core-vol&gt;/suite-install/yamlContent/itom-postgresql-single-svc.yaml). Container section, under image add lines<br>
	&nbsp; &nbsp; &nbsp; &nbsp; image: localhost:5000/hpeswitomsandbox/itom-postgresql:9.5.11-0021<br>
	&nbsp; &nbsp; &nbsp; &nbsp; ports:<br>
	&nbsp; &nbsp; &nbsp; &nbsp; - containerPort: 5432<br>
	&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hostPort: 5432 &nbsp;</li>
	<li>Once YAML is modified execute below command for the changes to take effect.&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; kubectl apply -f &lt;core-vol&gt;/suite-install/yamlContent/itom-postgresql-single-svc.yaml</li>
</ol>

<h4>Postgres High Available</h4>
Steps to follow to expose ITOM Postgres port outside of Kubernetes cluster

<ol>
	<li>Add the following line to both the pg_hba.conf files;<br>
	&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;host &nbsp; &nbsp;all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.0.0.0/0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; md5<br>
	<db-node1-vol>/baseinfra-1.0/postgresql95HA/node1data/pg_hba.conf<br>
	<db-node2-vol>/baseinfra-1.0/postgresql95HA/node2data/pg_hba.conf </db-node2-vol></db-node1-vol></li>
	<li>Add hostPort: 5432 to the file, as shown below &lt;core-vol&gt;/suite-install/yamlContent/itom-postgresql-pool-svc.yaml<br>
	ports:<br>
	&nbsp; &nbsp; &nbsp; &nbsp; - containerPort: 5432<br>
	&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hostPort: 5432<br>
	&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; name: pg-port<br>
	&nbsp; &nbsp; &nbsp; &nbsp; - containerPort: 5050<br>
	&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; name: pgrest-port</li>
	<li>Once yaml is modified execute below command for the changes to take effect.<br>
	kubectl apply -f &nbsp;&lt;core-vol&gt;/suite-install/yamlContent/itom-postgresql-pool-svc.yaml</li>
</ol>

<h3>Bring down old version of HCM</h3>
You need to bring down the old version of HCM only if you are reusing the HCM databases with the new version. You can skip this step if you have cloned the database.<br>
Additionally, you have to bring down the HCM if you are going to make the finally switch to the new HCM version. This is to prevent any additional artifacts (subscriptions, designs etc.) being created in the older version of HCM.<br>
/opt/kubernetes/scripts/cdfctl.sh runlevel set -l DOWN -n &lt;hcm-namespace&gt;
<h3>Bring down HCM 2020.05</h3>
Before bringing down, note down the following secrets on the HCM 2020.05 to use it later.<br>
kubectl exec -it &lt;csa-pod&gt; -n &lt;hcm-namespace&gt; -c hcm-csa -- get_secret HCM_IDM_SVC_PASSWORD<br>
<span style="color:#e67e22;">OUTPUT : PASS=qpfy_an63?LL.9i8</span><br>
Now you can bring down HCM using the following commands;<br>
kubectl get ns<br>
/opt/kubernetes/scripts/cdfctl.sh runlevel set -l DOWN -n &lt;hcm-namespace&gt;
<h3>Migrate IDM&nbsp;</h3>

<h4>Recreate IDM database</h4>
We need to recreate the IDM database in the new version of HCM installation since the IDM would have initialized with the default seeded user and credentials, we need to clear all data in IDM and migrate from older IDM database and then reinitialize with HCM seeded user data. Login to HCM 2020.05 machine

<ol>
	<li>Stop IDM<br>
	cd &lt;core-vol&gt;/suite-install/yamlContent/<br>
	kubectl delete -f idm.yaml</li>
	<li>If the database used to install HCM is Internal Postgres, follow the below steps
	<ol>
		<li>Stop Internal Postgres<br>
		cd &lt;core-vol&gt;/suite-install/yamlContent/<br>
		kubectl delete -f itom-postgresql-single-svc.yaml</li>
		<li>Move the postgres folder to a backup location<br>
		mkdir ~/backupPG<br>
		cd <db-single-vol>/baseinfra-1.0<br>
		mv postgresql106 ~/backupPG</db-single-vol></li>
		<li>Start Internal Postgres<br>
		cd <core-vol>/suite-install/yamlContent/<br>
		kubectl create -f itom-postgresql-single-svc.yaml</core-vol></li>
	</ol>
	</li>
	<li>If the database used to install HCM is External Oracle or Postgresql, then back up the database following the vendor documentation. Drop and create a new database based on the HCM document.</li>
	<li>Start IDM and Login to CDF management portal<br>
	cd &lt;core-vol&gt;/suite-install/yamlContent/<br>
	kubectl create -f idm.yaml<br>
	Login to CDF management portal to ensure you can access the portal</li>
</ol>

<h4>Reset the IDM password</h4>
kubectl exec -it idm-7f44898bf6-h4q44 -n core -c idm -- bash<br>
sh /idmtools/idm-installer-tools/idm.sh databaseUser resetPassword -org Provider -name "admin" -plainPwd "&lt;new-temp-password&gt;"<br>
Login into management console and reset password correctly to the password which you had used while installation HCM.
<h4>Create idmTransportUser in IDM</h4>
kubectl exec -it &lt;idm-pod&gt; -n core -c idm -- get_secret idm_transport_admin_password<br>
<span style="color:#e67e22;">OUTPUT : PASS=CqeSFXzWvb3Wdw==</span><br>
echo -n transport_admin:CqeSFXzWvb3Wdw== | base64<br>
<span style="color:#e67e22;">OUTPUT: dHJhbnNwb3J0X2FkbWluOkNxZVNGWHpXdmIzV2R3PT0=</span><br>
Replace the base64 encoded password in the below curl commands against the authorization header.
<pre><code class="language-vim">curl -k -X POST \
  https://arunp-hcm-02-m1.swinfra.net:5443/idm-service/v2.0/tokens \
  -H 'accept: application/json' \
  -H 'authorization: Basic dHJhbnNwb3J0X2FkbWluOkNxZVNGWHpXdmIzV2R3PT0=' \
  -H 'cache-control: no-cache' \
  -H 'content-type: application/json' \
  -d '{
    "passwordCredentials": {
        "username": "admin",
        "password": "&lt;hcm-password&gt;"
    },
    "tenantName": "Provider"
}'
</code></pre>
<br>
Extract the token from the above command and replace it against the x-auth-token in the below curl command.<br>
&nbsp;
<pre><code>curl -k -X POST \
  https://arunp-hcm-02-m1.swinfra.net:5443/idm-service/api/system/jsondata \
  -H 'accept: application/json' \
  -H 'authorization: Basic dHJhbnNwb3J0X2FkbWluOkNxZVNGWHpXdmIzV2R3PT0=' \
  -H 'cache-control: no-cache' \
  -H 'content-type: application/json' \
  -H 'x-auth-token: eyJ0eXAiOiJKV1MiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIyYzkwY2RhZjcxMmZmOGJkMDE3MTJmZjkwNmY2MDEwMiIsImlzcyI6IklkTSAxLjI3LjAiLCJjb20uaHBlLmlkbTp0cnVzdG9yIjpudWxsLCJleHAiOjE1ODU2NTExMjAsImNvbS5ocC5jbG91ZDp0ZW5hbnQiOnsiaWQiOiIyYzkwY2RhZjcxMmZmOGJkMDE3MTJmZjkwMWUyMDBhZiIsIm5hbWUiOiJQcm92aWRlciIsImVuYWJsZWQiOnRydWV9LCJwcm4iOiJhZG1pbiIsImlhdCI6MTU4NTY0OTMyMCwianRpIjoiZTIyNWNjZjEtNWQyYi00NzBhLWI3N2ItODIzZjgzNzMxMDc4In0.jnFuSFzXicWl_pP_a6VQSLbRB5JC7KVsfzczw-HUgh0' \
  -d '[{
        "operation": "ADD_OR_UPDATE",
        "type": "databaseUser",
        "names": {
            "organizationName": "PROVIDER"
        },
        "attributes": {
            "name": "admin",
            "password": "&lt;hcm_password&gt;",
            "type" : "INTERNAL_SEEDED_USER"
        }
    },
   {
        "operation": "ADD_OR_UPDATE",
        "type": "databaseUser",
        "names": {
            "organizationName": "IdMIntegration"
        },
        "attributes": {
            "name": "idmTransportUser",
              "password": "qpfy_an63?LL.9i8",
             "type" : "INTEGRATION_USER"
        }
    }]'</code></pre>
&nbsp;</html>