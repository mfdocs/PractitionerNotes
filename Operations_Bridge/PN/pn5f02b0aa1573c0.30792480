<html><h2>Introduction</h2>
<span style="font-size:11pt"><span style="font-family:Calibri,sans-serif">Customers who are willing to upgrade to the latest version of OpsBridge Suite 2019.11, has to go through multiple (quarterly) upgrades, since there is no direct upgrade supported so far. To avoid the huge effort, time and complexity the aberrant suggestion was to go ahead with a plan to migrate their current environment WITHOUT undergoing multiple HOPS.</span></span><br>
<br>
<span style="font-size:11pt"><span style="line-height:107%"><span style="font-family:Calibri,sans-serif">Customers who are running their PRODUCTION environment in OpsBridge Suite with embedded Postgres and lots of integrations with Operations Agent (incl. Management packs / OpsC) and SiS servers, etc., also need to be preserved for upgrade use case.</span></span></span><br>
<span style="font-size:11pt"><span style="line-height:107%"><span style="font-family:Calibri,sans-serif">This document tries to capture every detailed aspect which needs to be followed to achieve a successful migration, without (or minimal) Configuration DATA loss (from the Postgres side of the house). VERTICA DB (used for COSO) is NOT considered, as there is NO migration plan.</span></span></span>

<div></div>

<div class="Admonition_Note"><span style="font-size:11pt"><span style="line-height:107%"><span style="font-family:Calibri,sans-serif">Scope of migration: Any OpsBridge suite with embedded Postgres (not less than 2018.11 version) to OpsBridge suite 2019.11 with external Postgres.</span></span></span></div>

<h2>Migration Pre-requisites</h2>

<h3>Install mlocate package on Master node</h3>

<div>In case if you see that ‘mlocate’&nbsp;&nbsp;package is not installed on the CentOS, Master node. Run the below commands (after consulting your system admin).</div>

<pre><code class="language-basic">yum install mlocate -y</code></pre>

<h3>Install jq package on Master node</h3>
In case if you see that ‘jq’&nbsp; package is not installed on the CentOS, Master node. Run the below commands (after consulting your system admin).

<pre><code>yum install epel-release -y
yum install jq -y</code></pre>

<h3>Install External Postgres</h3>
Install supported Postgres server version on an external database server. Refer OpsBridge 2019.11 installation document for the supported Postgres version.&nbsp;<br>
External Postgres server must be accessible to Master node.&nbsp;Ensure Postgres server has enough disk space required for database restore. Refer embedded Postgres size as illustrated in following section as a reference to estimate disk size required.&nbsp;
<h3><span style="color: rgb(0, 0, 0); font-family: MetricHPE_Medium; font-size: 20px;">Configure NFS volumes</span></h3>
Configure two new NFS volumes:

<ol>
	<li>&nbsp;The first volume will be used to store&nbsp;backup data for this migration workflow.</li>
	<li>The second volume needs to be configured as per OpsBridge suite 2019.11 install document. This volume will be used for installation of OpsBridge 2019.11.</li>
</ol>

<div class="Admonition_Note">Note:&nbsp; Any additional pre-requisites as per OpsBridge 2019.11 install document can be pre-configured to reduce migration window.&nbsp;</div>

<h2>Download Scripts</h2>

<div>Download the scripts required for this workflow from <strong>here</strong>. Unzip the file and copy the scripts to Master and external Postgres server.&nbsp;<br>
<strong>&lt;Script-Link&gt;</strong></div>

<h2>Back up Cluster</h2>

<h3 style="margin-top: 3px;">Note down all db connections in BVD (Skip if BVD capability not installed)</h3>
Login to BVD UI and navigate to Settings -&gt; Data Collectors. Note down the db connections created in BVD for data collectors. The db connection need to be re-created manually on BVD post migration to 2019.11.<br>
<img alt="" border="0" file="" height="352" hspace="0" src="https://docs.microfocus.com/mediawiki/images/2/2b/bvd1-pre-req.jpg" style="width:672px;height:352px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="672">
<h3><br>
Note down all users, user groups and user roles attributes in BVD (Skip if BVD capability not installed)</h3>
Login to BVD UI and navigate to Settings -&gt; Users and Roles. &nbsp;Note down all the users, user groups and user roles attributes which is created in BVD. This has to be restored manually if attributes for these objects are observed to be missing post migration.<br>
<span style="color: rgb(0, 0, 0); font-family: MetricHPE_Medium; font-size: 20px;">Configure Event Auto Archiving</span><br>
Follow the instructions&nbsp;<a href="https://docs.microfocus.com/itom/Operations_Bridge:2019.11/oprArchiveEventsCLI" target="_blank">here</a> for Event Archiving.

<h3>Clear UCMDB history</h3>
Follow the instructions <a href="https://docs.microfocus.com/itom/Operations_Bridge_Manager:2019.11/ServerAdminPurgingTr" target="_blank">here</a> to clear/purge the UCMDB history

<h3>Get the current embedded Postgres Version (optional)</h3>
Execute below command to get embedded Postgres pod name

<pre><code>kubectl get pods -n core |grep postgres | awk 'NR==1 {print $1}'</code></pre>
Execute below command on the Master node to note Postgres version

<pre><code>kubectl exec -it  &lt;postgres-pod-name&gt;  --namespace core  -- bash -c "psql -U postgres -d postgres -c 'SHOW server_version;'"</code></pre>

<h3>Get the DB list from the embedded Postgres</h3>
Execute this command on the Master node.&nbsp; The databases listed would be targeted for migration. The list of databases here may vary based on the capabilities selected during OpsBridge installation. Verify these databases are successfully restored on External postgres after restore operation.

<pre><code>kubectl exec -it &nbsp;&lt;postgres-pod-name&gt; --namespace core -c itom-postgresql-default -- bash -c "psql -U postgres &nbsp;-c 'SELECT datname FROM pg_database WHERE datistemplate = false and datname != \$\$replication_db\$\$ and datname != \$\$postgres\$\$;'"
</code></pre>

<h3>Check suite db ownership on embedded POSTGRES (Optional)</h3>
As a super user, run the below command to check ownership rights to OpsBridge Suite DB list. Choose the database name from the above section to list ownership.&nbsp;

<pre><code>kubectl exec -it &nbsp;&lt;postgres-pod-name&gt; --namespace core &nbsp;-c itom-postgresql-default &nbsp;-- bash -c "psql -U postgres -d postgres &nbsp;-c '\l+'" | grep -E 'Owner|&lt;database-name&gt;'</code></pre>

<h3>Get the Total embedded database size (Optional)</h3>
As a super user, run the below command to get the size of the DB.&nbsp;

<pre><code>kubectl exec -it &nbsp;&lt;postgres-pod-name&gt; &nbsp;--namespace core -c itom-postgresql-default -- bash -c "psql -U postgres -d postgres -c 'SELECT sum(pg_database_size(pg_database.datname)/1024.0) FROM pg_database ;'"</code></pre>

<h3>Execute backup script&nbsp;</h3>
Download and execute backupScript.sh script on Master node to backup following configurations:

<ol>
	<li>Certificates:&nbsp; chain.pem, key.pm,&nbsp;RE_ca&nbsp;</li>
	<li>Configmaps</li>
	<li>Embedded Postgres configuration files: postgressql.conf &amp; pg_hba.conf</li>
	<li>UCMDB Master key&nbsp;</li>
	<li>Embedded Postgres user credentials.&nbsp;</li>
	<li>Embedded Postgres database&nbsp;</li>
</ol>
Script requirements&nbsp;

<ol>
	<li>Must be executed with super user permission on Master node</li>
	<li>Ensure all pods are running before executing the script&nbsp;</li>
</ol>
The script will save backed up data under &lt;NFS-Folder&gt;/opsb_migration/ directory. DO NOT DELETE any data from this folder as it will be used for database restore and post migration step workflows.&nbsp;<br>
Download the script on master node and assign required execution permission before script execution.
<pre><code class="language-bash">chmod +x backupScript.sh
./backupScript.sh</code></pre>
&nbsp;

<div class="Admonition_Note">&nbsp;Note: &nbsp;<br>
1.&nbsp;&nbsp;It is recommended to take backup on NFS mount which has sufficient disk space to hold all the backup files including database backup<br>
2.&nbsp;&nbsp;To maintain embedded Postgres data consistency this script will scale down the deployment under opsbridge-xxx namespace.&nbsp;</div>
Use scp to transfer database backup and configuration files from master to remote postgres server.

<pre><code>scp -r &lt;NFS-Folder&gt;/opsb_migration/&lt;time-stamp&gt;/dbbackups/*.dump &nbsp; &nbsp; root@&lt;External-Postgres-hostname&gt;:/var/2018.11.Backup/dbbackups
scp -r &lt;NFS-Folder&gt;/opsb_migration/&lt;time-stamp&gt;/conf/* &nbsp; &nbsp; &nbsp;root@&lt; External-Postgres-hostname&gt;:/var/2018.11.Backup/conf
</code></pre>

<h2>Postgres DB migration</h2>
Perform these steps on external Postgres server.

<h3>Configuration file changes</h3>
Add the below entries at the end of the pg_hba.conf file

<pre><code>host all all 0.0.0.0/0 md5
host all all ::/0 md5
</code></pre>
<br>
Edit postgresql.conf file for&nbsp;listen_addresses , port and lo_compat_privileges parameters to as shown below
<pre><code>listen_addresses = '*'
port = 5432
lo_compat_privileges = on
</code></pre>
<br>
Restart postgres service
<pre><code>systemctl restart postgresql-10.service</code></pre>
Get the current external Postgres Version (optional)<br>
Once logged in as postgres super user into database, run the below command.&nbsp;
<pre><code>SHOW server_version ;</code></pre>
Check External Postgres connection with super user. From the master node, run the below command

<pre><code>psql "dbname=&lt;dbname&gt; password=&lt;password&gt; host=&lt;postgres_node&gt; port=&lt;postgres_port&gt; user=&lt;super_user&gt;"</code></pre>

<h3>Execute database restore script&nbsp;</h3>
Download &amp; Execute restoredbSchema.sh script on External Postgres Server to restore database backup. This script will:

<ol>
	<li>Restore database using .dump files&nbsp;</li>
	<li>Set database user credentials for postgres &amp; cdfidm users to one existed in embedded postgres setup.</li>
</ol>
Script requirements:&nbsp;

<ol>
	<li>Script supports restore operation only for database backup files generated using backupScript.sh in the previous step</li>
	<li>Must be executed with super user permission on External Postgres server</li>
	<li>Ensure .dump and config.properties files are available on External Postgres server and have read permissions.</li>
	<li>Database instance must be a fresh installed instance.&nbsp;</li>
</ol>
Assign required execution permission before script execution as below

<pre><code>chmod +x restoredbSchema.sh
./restoredbSchema.sh
</code></pre>
&nbsp;

<div class="Admonition_Note">Note: &nbsp;<br>
1.&nbsp; Script uses Postgres database 'postgres' user (superuser) to restore the backup on Postgres server<br>
2.&nbsp;&nbsp;Note down cdfidm &amp; postgres user credentials post execution of this script (also available in config.properties file). &nbsp;In the later steps you need to use cdfidm user credentials to connect to External Postgres server while installing OpsBridge 2019.11.&nbsp; &nbsp; &nbsp;</div>
Try connecting to the database as cdfidm user. Execute the command from master node and check database table ownership. Use the password from <strong>config.properties</strong> file&nbsp;

<pre><code>psql "dbname=&lt;dbname&gt; password=&lt;password&gt; host=&lt;postgres_node&gt; port=5432 user=cdfidm"
\dt+</code></pre>

<h2>Bring down the cluster&nbsp;</h2>
Make sure all the PODS are up and running.&nbsp;Shut down Suite pods by Running the below command:

<pre><code class="language-bash">${K8S_HOME}/scripts/cdfctl.sh -f runlevel set -l DOWN</code></pre>
<br>
Make sure that all the PODS are DOWN and the Suite too. Ignore the Completed pods.<br>
List of pods in Core namespace post execution of cdfctl.sh command
<pre><code>kubectl get pods -n core&nbsp;</code></pre>
<br>
<img align="left" alt="" border="0" file="" height="343" hspace="0" src="/mediawiki/images/pn_images/pn_image_5f0495f615c749.27757956.jpeg" style="width:800px;height:343px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="800"><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
List of pods in OpsBridge namespace post execution of cdfctl.sh
<pre><code>kubectl get pods -n &lt;OpsBridge-namespace&gt;</code></pre>
<br>
<img alt="" border="0" file="" height="94" hspace="0" src="https://docs.microfocus.com/mediawiki/images/d/d1/cluster-down-2.jpg" style="width:705px;height:94px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="705">
<h3>Take a snapshot of Master and Worker nodes (Optional)</h3>
Run the below command on all the Worker Nodes, followed by the Master Nodes

<pre><code class="language-bash">${K8S_HOME}/bin/kube-stop.sh -y</code></pre>
<br>
<img alt="" border="0" file="" height="91" hspace="0" src="https://docs.microfocus.com/mediawiki/images/8/83/kube-down1.jpg" style="width:791px;height:91px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="791"><br>
<br>
Check if there any mount points still active. On the Master node, run the following command. If you see any residual, then kindly run the second command to un-mount the same.
<pre><code class="language-bash">df -k | grep kubernetes
for f in $(df | awk '/kubernetes/ {print $6}'); do umount $f; done
</code></pre>
Shut down the VM’s and take a snapshot of the same Virtual Machines.

<div class="Admonition_Note">Note: It is recommended to take snapshot of Master and Worker nodes in case restore of this setup is needed at later point in time.</div>
Run the below command on the Master nodes, followed by worker nodes

<pre><code class="language-bash">${K8S_HOME}/bin/kube-start.sh</code></pre>
Bring up Suite pods by Running the below command:

<pre><code class="language-bash">${K8S_HOME}/scripts/cdfctl.sh runlevel set -l UP -f</code></pre>

<h3>Check the status of Agent Nodes (Optional)</h3>
Once the cluster is totally down, one would see that the Integrations like Agent and SiS, will be in buffering state.<br>
<img alt="" border="0" file="" height="324" hspace="0" src="https://docs.microfocus.com/mediawiki/images/b/b7/agent-state.jpg" style="width:708px;height:324px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="708">
<h2>Uninstall OpsBridge</h2>
Refer to the uninstallation document corresponding to the OpsBridge version you have.&nbsp;<br>
For example, uninstallation document for OpsBridge 2018.11 with embedded Postgres can be found <a href="https://docs.microfocus.com/itom/Operations_Bridge:2018.11/Uninstall_OpsB" target="_blank">here</a>

<h2>Install OpsBridge 2019.11&nbsp;</h2>

<h4>Maintain the old Administrator Password</h4>
<img alt="" border="0" file="" height="191" hspace="0" src="https://docs.microfocus.com/mediawiki/images/d/d4/install-cli-1.jpg" style="width:755px;height:191px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="755">
<h4>Select Capabilities</h4>
Select the capabilities as chosen in previous OpsBridge installation.<br>
<img alt="" border="0" file="" height="272" hspace="0" src="https://docs.microfocus.com/mediawiki/images/e/ee/install-capability.jpg" style="width:687px;height:272px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="687">
<h4>Database details</h4>
Maintain the same entries for Database Name, User and Password. Ignore the warning and click <strong>Yes</strong>.<br>
<img alt="" border="0" file="" height="319" hspace="0" src="https://docs.microfocus.com/mediawiki/images/7/7e/install-db-1.jpg" style="width:771px;height:319px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="771"><br>
<img alt="" border="0" file="" height="105" hspace="0" src="https://docs.microfocus.com/mediawiki/images/8/88/install-db-2.jpg" style="width:295px;height:105px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="295">
<h4>Deployment Size</h4>
Choose the deployment size in accordance to the current requirement

<h4>Single Master to Multi-Master?</h4>
Single Master to Single Master, keep the same FQDN as that of the previous set up as the External Hostname.<br>
<br>
Single Master to Multi Master (for Master High availability), make sure you configure the previous value of External Hostname as a VIP and update the same in the field External Hostname. Which would mean, one would need 3 FRESH nodes to be added as Master Nodes. And the old Master’s IP and FQDN should be used as HA_VIRTUAL_IP. The Old node should NOT be running.<br>
<br>
This is very crucial for integrations.<br>
The Agents and SiS nodes would be in buffering state till the DOWN time. Once the Cluster and the capabilities are UP, and the connectivity is established, the buffered events should reach to the OMi event Browser.
<h4>External Hostname and Custom Certificates</h4>
In the Connection page (after selecting the Deployment Size), make sure that the External Hostname is properly configured.

<table class="MsoTableGrid" style="border-collapse:collapse; border:none">
	<tbody>
		<tr>
			<td style="border-bottom:2px solid black; width:138px; padding:0in 7px 0in 7px; background-color:#bfbfbf; border-top:2px solid black; border-right:2px solid black; border-left:2px solid black" valign="top"><font face="Calibri, sans-serif"><span style="font-size: 14.6667px;"><b>Previous OpsBridge Installation</b></span></font></td>
			<td style="border-bottom:2px solid black; width:168px; padding:0in 7px 0in 7px; background-color:#bfbfbf; border-top:2px solid black; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif"><b><span style="color:black">OpsBridge 2019.11<br>
			Installation</span></b></span></span></span></td>
			<td style="border-bottom:2px solid black; width:318px; padding:0in 7px 0in 7px; background-color:#bfbfbf; border-top:2px solid black; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif"><b><span style="color:black">External Hostname</span></b></span></span></span></td>
		</tr>
		<tr>
			<td style="border-bottom:2px solid black; width:138px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:2px solid black" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Multi-Master</span></span></span></td>
			<td style="border-bottom:2px solid black; width:168px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Multi-Master</span></span></span></td>
			<td style="border-bottom:2px solid black; width:318px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Keep the same as used in previous OpsBridge installation, which would be the HA_VIRTUAL_IP</span></span></span></td>
		</tr>
		<tr>
			<td style="border-bottom:2px solid black; width:138px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:2px solid black" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Single Master</span></span></span></td>
			<td style="border-bottom:2px solid black; width:168px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Single Master</span></span></span></td>
			<td style="border-bottom:2px solid black; width:318px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Same of the Master FQDN</span></span></span></td>
		</tr>
		<tr>
			<td style="border-bottom:2px solid black; width:138px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:2px solid black" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Single Master</span></span></span></td>
			<td style="border-bottom:2px solid black; width:168px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Multi-Master</span></span></span></td>
			<td style="border-bottom:2px solid black; width:318px; padding:0in 7px 0in 7px; border-top:none; border-right:2px solid black; border-left:none" valign="top"><span style="font-size:11pt"><span style="line-height:normal"><span style="font-family:Calibri,sans-serif">Configure the External Hostname of previous OpsBridge installation as the HA_VIRTUAL_IP of the new 2019.11 set up. And this would mandate new Master nodes.</span></span></span></td>
		</tr>
	</tbody>
</table>
Select the option ‘Use custom certificates’ and upload the respective RE_CA.CRT, CHAIN.PEM and KEY.PM exported from the previous installation as shown below.<br>
These certificates are backed up at NFS folder as part of backup script execution.<br>
<img alt="" border="0" file="" height="354" hspace="0" src="https://docs.microfocus.com/mediawiki/images/f/f8/install-cert.jpg" style="width:637px;height:354px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637">
<h4>Add the Worker Nodes&nbsp;</h4>
Make sure you get the required number of Worker Nodes, based on the sizing calculator available <a href="https://docs.microfocus.com/itom/Operations_Bridge:2019.11/SizingCalculator" target="_blank">here</a>.

<h4>File Storage</h4>
Use the same File Storage Server, with different Exported Paths (if it has enough space) or use a new NFS location as configured as part of pre-requisite.<br>
<img alt="" border="0" file="" height="155" hspace="0" src="https://docs.microfocus.com/mediawiki/images/8/86/install-filestorage.jpg" style="width:637px;height:155px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637">
<h4>Deploy Operations Bridge</h4>
Make sure you enter the OLD values which were used in the previous OpsBridge installation set up while deploying the OpsBridge Suite<br>
Deployment Reference available <a href="https://docs.microfocus.com/itom/Operations_Bridge:2019.11/DeployOpsBridgeSuite" target="_blank">here</a><br>
<strong>Example:&nbsp;</strong><br>
Choose Custom configuration
<ul>
	<li>Connection</li>
</ul>
Use the certificate generated by the ITOM platform or use Upload certificates (in case if you had uploaded custom certificates during previous OpsBridge installation)<br>
<img alt="" border="0" file="" height="194" hspace="0" src="https://docs.microfocus.com/mediawiki/images/5/5b/install-opsb-cert.jpg" style="width:637px;height:194px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637"><br>
JMX password, set the password for the Jmx administrator to same as configured in previous OpsBridge installation<br>
Database settings, set the names to same as configured in previous OpsBridge installation. In this case it will be the name of databases restored using embedded database.<br>
<img alt="" border="0" file="" height="295" hspace="0" src="https://docs.microfocus.com/mediawiki/images/5/56/install-db-name.jpg" style="width:637px;height:295px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637"><br>
Enable high availability for Operations Bridge Manager, if it was set in previous OpsBridge installation. If it was not, you can still opt for High Availability for OpsBridge 2019.11<br>
<img alt="" border="0" file="" height="208" hspace="0" src="https://docs.microfocus.com/mediawiki/images/3/37/install-opsb-HA.jpg" style="width:637px;height:208px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637"><br>
Select the Management Packs which were chosen at the time of previous OpsBridge installation.<br>
BVD Login, use suite default administrative user account in case if you didn’t had custom credentials set in previous OpsBridge installation.<br>
BVD Database, set the names to same as configured in previous OpsBridge installation
<div class="Admonition_Note"><strong>Note</strong>: The Vertica DB, user and credentials needs to be provided as per the new set up.</div>
<strong><img alt="" border="0" file="" height="327" hspace="0" src="https://docs.microfocus.com/mediawiki/images/2/20/install-vertica-1.jpg" style="width:637px;height:327px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637"><br>
<img alt="" border="0" file="" height="288" hspace="0" src="https://docs.microfocus.com/mediawiki/images/3/3c/install-vertica-2.jpg" style="width:637px;height:288px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637"><br>
<img alt="" border="0" file="" height="171" hspace="0" src="https://docs.microfocus.com/mediawiki/images/a/a8/install-vertica-3.jpg" style="width:637px;height:171px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637"></strong>

<h2>Restore the MASTER_KEY to ucmdb POD</h2>
Update UCMDB MASTER_KEY key with the value available in config.properties.&nbsp;<br>
Execute below command :
<pre><code>kubectl exec -ti &nbsp;&lt;ucmdb-pod-name&gt; &nbsp;--container ucmdb -n &lt;Opsb-namespace&gt; &nbsp;-- /bin/sh -c "update_secret MASTER_KEY &nbsp;&lt;UCMDB_MASTER_KEY&gt;&gt;"</code></pre>
For example:

<div class="Admonition_Note">kubectl exec -ti ucmdb-76689d476b-hwvl4 --container ucmdb -n opsbridge-zcmn0 &nbsp;-- /bin/sh -c "update_secret MASTER_KEY &nbsp; iDA+UlD4i4HYFbyf+ZFrtCRvKbGLkRe4bRIjrsP/ksWJX3IzAoL58u4ybA+HxxxVMB"</div>

<h2>Configure the YAML</h2>
Edit the respective kubernetes objects like deployments, replica sets etc., to match to that of the old configurations and values. Refer the config map (.yaml files) backed up earlier using backup script.&nbsp;

<h2>For Streaming use cases&nbsp;</h2>
In order to continue streaming from Sources like Operations Agent node, Site Scope, BPM and APM, one must update the “MF CDF RID CA” as the Trusted Certificates on both OBM and then on the connected streaming data sources.

<h3>Get the new RID CA</h3>
Run the below command to get RID CA and copy it inside the OBM container&nbsp;

<pre><code>kubectl cp core/&lt;suite-conf-pod-opsbridge-pod&gt;:/var/run/secrets/boostport.com/trustedCAs/RID_ca.crt /tmp/RID_ca.crt -c kubernetes-vault-renew</code></pre>

<h3>Import RID CA</h3>

<h4>OBM container</h4>
Copy the RID_ca.crt into the OBM container. And then login to the OBM pod and run the following commands to update the Trusted Certificates.

<pre><code>kubectl cp /tmp/RID_ca.crt &lt;opsbridge-namespace&gt;/omi-0:/tmp -c omi&nbsp;&nbsp; &nbsp;
/opt/OV/bin/ovcert -list
/opt/OV/bin/ovcert -remove "&lt;MF CDF RID CA on &gt;" -ovrg server -f
/opt/OV/bin/ovcert -importtrusted -file /tmp/RID_ca.crt -ovrg server
/opt/OV/bin/ovcert -remove "&lt;MF CDF RID CA on &gt;" -f
/opt/OV/bin/ovcert -importtrusted -file /tmp/RID_ca.crt
</code></pre>
Once done, restart the ovcs on OBM pod (execute on both omi-0 and omi-1 pods if in HA)

<pre><code>/opt/OV/bin/ovc -restart ovcs</code></pre>

<h4>OBM Classic</h4>
Transfer the file securely to the OBM. And run the same commands as shared above. Make sure you provide the right location of RID_ca.crt. And also restart ‘ovcs’

<h3>Update on Data Sources</h3>

<h4>Linux Nodes</h4>

<pre><code>/opt/OV/bin/ovcert -list
/opt/OV/bin/ovcert -remove "&lt;MF CDF RID CA on &gt;" -ovrg server -f
/opt/OV/bin/ovcert -updatetrusted
</code></pre>

<h4>Windows Nodes</h4>

<pre><code>ovcert -list
ovcert -remove "&lt;MF CDF RID CA on &gt;" -ovrg server -f
ovcert -updatetrusted
</code></pre>

<h4>AIX nodes</h4>

<pre><code>/usr/lpp/OV/bin/ovcert -list
/usr/lpp/OV/bin/ovcert -remove "&lt;MF CDF RID CA on &gt;" -ovrg server -f
/usr/lpp/OV/bin/ovcert -updatetrusted
</code></pre>

<h3>Validate the connectivity</h3>
Check the details of the RID CA on Server and Node<br>
If you have keytool installed on your Linux nodes, then run the below command:
<pre><code>keytool -printcert -v -file ca.crt | egrep "Certificate\[|Owner|Issuer|MD5"</code></pre>
Wherein, the ca.crt would the result of the below command (on both OBM and Managed streaming nodes)

<div class="Admonition_Note">On Linux :&nbsp;/opt/OV/bin/ovcert -exporttrusted -file ca.crt<br>
On AIX&nbsp; :&nbsp; /opt/OV/bin/ovcert -exporttrusted -file ca.crt</div>
<br>
<img alt="" border="0" file="" height="121" hspace="0" src="https://docs.microfocus.com/mediawiki/images/c/cd/validate-connectivity.jpg" style="width:637px;height:121px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637">
<h4>Using the bbcutil ping</h4>
One can also validate to see if there is NO eSSLError, while executing bbcutil -ping to the Data Receiver Endpoint

<div class="Admonition_Note">On Linux: /opt/OV/bin/bbcutil -ping https://&lt;External_HostName&gt;:36500/itomdi/receiver<br>
On AIX: /usr/lpp/OV/bin/bbcutil -ping https://&lt;External_HostName&gt;:36500/itomdi/receiver<br>
On Windows: bbcutil -ping https://&lt;External_HostName&gt;:36500/itomdi/receiver</div>
<br>
<strong><img alt="" border="0" file="" height="81" hspace="0" src="https://docs.microfocus.com/mediawiki/images/c/cf/validate-bbutil.jpg" style="width:637px;height:81px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="637"></strong>

<h2>Restore BVD db connections</h2>
You need to set up database connection in BVD 2019.11 as shown below with the external database that was used for BVD with previous OpsBridge installation to ensure that the dashboard is able to display all the data elements. &nbsp;

<ol>
	<li>Click Setting and select <strong>Data Collectors</strong>.&nbsp;</li>
	<li>On <strong>Data Collectors</strong> page, click three dots (as shown below) and select <strong>DB Connection Setting</strong>.&nbsp;</li>
</ol>
<img alt="" border="0" file="" height="198" hspace="0" src="https://docs.microfocus.com/mediawiki/images/a/af/bvd-db-1.jpg" style="width:433px;height:198px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="433"><br>
&nbsp; &nbsp; &nbsp;3. Fill in all required details in <strong>SET UP DB CONNECTION</strong> form. The details you enter here should contain the same information as in previous BVD database connection.<br>
<img alt="" border="0" file="" height="800" hspace="0" src="https://docs.microfocus.com/mediawiki/images/6/64/bvd-db-2.jpg" style="width:476px;height:800px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="476"><br>
&nbsp; &nbsp; &nbsp;4.&nbsp;Click <strong>TEST CONNECTION </strong>to ensure the database connection.&nbsp;<br>
&nbsp; &nbsp; &nbsp;5. Click <strong>SAVE SETTINGS</strong>.&nbsp;<br>
Once you have set up the database connection, you need to run all the queries at least once in BVD 2019.11 to enable dashboards to show all the data elements.&nbsp;<br>
&nbsp;&nbsp; &nbsp;1. Click settings, select <strong>Data Collectors</strong> to list all the data or parameter queries.&nbsp;<br>
<img alt="" border="0" file="" height="81" hspace="0" src="https://docs.microfocus.com/mediawiki/images/f/f9/bvd-db-3.jpg" style="width:464px;height:81px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="464"><br>
&nbsp;&nbsp; &nbsp;2. Click edit button to view all the details of the query.&nbsp;<br>
&nbsp;&nbsp; &nbsp;3. Click <strong>RUN</strong> under Query*.<br>
<img alt="" border="0" file="" height="108" hspace="0" src="https://docs.microfocus.com/mediawiki/images/2/21/bvd-db-4.jpg" style="width:151px;height:108px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="151"><br>
&nbsp;&nbsp; &nbsp;4. After you run the query, click <strong>SAVE DATA QUERY</strong>.&nbsp;<br>
&nbsp;&nbsp; &nbsp;5. You need to edit and run all the queries listed under <strong>Data Collector</strong>.&nbsp;<br>
Once you perform all of the above steps, view the dashboards to verify whether you can see all the dashboard elements.<br>
For example, when you run a data query called <strong>Multicategory</strong> and save the query, you will be able to see the updated values on the dashboard. When you hover mouse-pointer over <strong>Multicategory</strong> under <strong>Data Channel</strong>, you will see when was the latest update made.<br>
<img alt="" border="0" file="" height="182" hspace="0" src="https://docs.microfocus.com/mediawiki/images/0/05/bvd-db-5.jpg" style="width:364px;height:182px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="364">
<h2>OBM User Roles</h2>
Post migration you may observe few custom user roles do not retain permissions granted in previous OpsBridge installation. &nbsp;Follow below steps to fix this issue:

<ol>
	<li>Login to OBM</li>
	<li>Navigate to Administration &gt; Users &gt; Users, Groups, and Roles menu in OBM.</li>
	<li>Select the role</li>
	<li>Edit the role</li>
	<li>Save Role</li>
</ol>

<h2>BVD Users &amp; Groups</h2>
In few cases It was observed that post migration BVD does not retain Users and Groups attributes. Hence edit the settings for each of these objects and restore them manually.&nbsp;

<h2>UCMDB license</h2>
Try logging to JMX-Console or to the local client using the &lt;RTSM&gt; user. In case if you get the below error, install this <a href="https://rdapps.swinfra.net/hotfix/#/hotfix/10075" target="_blank">Hotfix</a>.<br>
<img alt="" border="0" file="" height="105" hspace="0" src="https://docs.microfocus.com/mediawiki/images/b/b3/ucmdb-hotfix.jpg" style="width:293px;height:105px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;" vspace="0" width="293"><br>
<br>
&nbsp;</html>