<h1>Custom metric integration to the COSO Data Lake for OpsBridge reporting solutions</h1><p>This section describes how to extend the COSO Data Lake to collect custom metrics to enable custom reporting using Business Value Dashboard or your own BI reporting tools.<br></p><p>This section covers the following topics:</p><p></p><ul><li>Custom metric collection concepts</li><li>Metric life cycle</li><li>Steps to create your custom content</li><li>Fully functional end to end example</li></ul><p></p><h2>Custom metric collection concepts</h2><p>There are two approaches to ingesting Operations Agent custom metrics into the COSO Data Lake:<br></p><h3>Collection Services</h3><p>The Collection Service is a containerized micro service designed to centrally collect large amounts of data from the remote Operations Agents’ Performance Collection Component and store it in the COSO Data Lake. It supports collecting data from all Operations Agent supported platforms, and all supported versions. The Collection Service is horizontally scalable. It spawns one or more Agent Metric Collector containers, depending on the number of collections you configure, which in turn define the nodes from which to collect data.</p><p>This is the recommended approach where the data is used for reporting purposes and doesn’t require real time analytics or central thresholding.</p><p>You use the Content Administration Service, a containerized micro service, to configure the Collection Service to collect data from the Operations Agents on a scheduled basis.&nbsp; The data collection mechanism uses the CODA client APIs to connect to the Operations Agent, which uses HTTPS-based communications by default, and falls back to HTTP,&nbsp; if HTTPS is unavailable.&nbsp; Note that the Collection Service requires a certificate from OBM, before the agent metric collection can start.&nbsp; The Content Administration Service also configures the COSO Data Lake to store and manage the data.</p><h3>OBM policies</h3><p>OBM policies are used to collect data from any of these sources:</p><p></p><ul><li>XML File</li><li>Structured Log File</li><li>REST web service</li><li>Performance Collection Component</li></ul><p></p><p>In this case the data is typically used for real time graphing and central thresholding purposes, but it can also be used for reporting since it is stored in the COSO Data Lake. You deploy OBM policies to the Operations Agents that configure what data to send to the COSO Data Lake via an HTTPS POST and how frequently.</p><p>Metric Streaming Configuration policies are supported on all Operations Agent platforms.&nbsp; All other metric collection policy types are supported on Windows and Linux platforms only.</p><p>You use the Content Administration Service to configure the COSO Data Lake to store and manage the data.</p><p>The following diagram shows the components used in collecting custom metrics.</p><div><br></div><div><img src="https://docs.microfocus.com/mediawiki/images/PN/diag1.png"><br></div><p class="MsoNormal"><br></p><h2><img src="https://docs.microfocus.com/mediawiki/images/PN/diag2.PNG"><br></h2><h2><br></h2><h2>Metric life cycle</h2><p class="MsoNormal">You need to consider what metrics to collect, whether aggregation is required and how long to retain the data in the COSO Data Lake.</p><h3>Define</h3><p class="MsoNormal">This involves defining how the COSO Data Lake is configured to process custom metrics:<br></p><p class="MsoNormal"></p><ul><li>Database table(s) in Vertica</li><li>Kafka topic though which data is ingested (not applicable for the Agent Metric Collector of the Collection Service)</li><li>Connection between the Kafka topic and the database table (not applicable for the Agent Metric Collector of the Collection Service)</li></ul><p></p><p class="MsoNormal">This information is defined in a well-known JSON file format and configured using the Content Administration Service.<br></p><h3>Collect and ingest</h3><h4>Collection Service</h4><p class="MsoNormal">For the reporting use case, the recommended method of Operations Agent metric collection is to use the Collection Service.&nbsp; The metrics to collect, the agents from which to collect and how frequently to collect are defined in a well-known JSON file format and configured using the Content Administration Service.</p><h4>OBM policies</h4><p class="MsoNormal">If you use OBM policies to post the data to COSO, then you need to create, assign and deploy the policies.&nbsp; The policies contain which metrics to collect from the local agent and how frequently to send the data to the COSO Data Lake. The Operations Agent, apart from acting as a source of system performance metrics, also acts as a metric integration framework, and provides the following options to integrate metrics to the COSO Data Lake.</p><p class="MsoNormal"><br></p><p class="MsoNormal">Note: A <span class="MsoHyperlink"><a href="https://docs.microfocus.com/itom/Operations_Bridge:2019.05/ConfigureDataForwardingPolicies">Data
Forwarding</a></span> policy is also required to match the data from the
collection policies and post it to the URL of the target COSO system.<br></p><p class="MsoNormal"><o:p></o:p></p><p class="MsoNormal">You can also stream out-of-the-box system metrics to COSO
via <span class="MsoHyperlink"><a href="https://docs.microfocus.com/itom/Operations_Bridge:2019.05/ConfigureMetricStreamingConfigurationPolicies">Metric
Streaming Configuration</a></span> policies.<o:p></o:p></p><h3><span lang="EN-AU">Aggregate / Roll up /
Forecast<o:p></o:p></span></h3><p class="MsoNormal"><span lang="EN-AU">The raw
metrics in the COSO Data Lake can be aggregated to hourly, daily, percentile,
or one of the similar supported aggregations by the COSO Data Lake capability, forecast,
or rolled up using custom functions desired by the user.&nbsp;</span>Aggregation
rules, forecast and custom roll up functions are defined as rules in a JSON
file format and configured using the Content Administration Service.</p><h3><span lang="EN-AU">Aging<o:p></o:p></span></h3><p class="MsoNormal"><span lang="EN-AU">Metrics in the
COSO Data Lake are deleted based on the retention profiles associated with the
data sets. Each data set, which internally translates to a table in the
database, can have one associated retention profile.&nbsp;</span>Retention
profiles are defined in a JSON file format and configured using the Content
Administration Service.</p><h2><span lang="EN-AU">Content configuration
overview<o:p></o:p></span></h2><p class="MsoNormal"><span lang="EN-AU">The reporting
content for the COSO Data Lake is packaged as a ZIP file with a well-known
folder structure where each folder contains a specific type of artifact.&nbsp; The supported artifacts are:</span></p><p class="MsoNormal"><span lang="EN-AU" style="text-indent: -0.25in;"></span></p><ul><li>Metric (schema) definition</li><li>Collection definition for the Operations Agent data source</li><li>Data enrichment definition</li><li>Custom roll up definition</li><li>Forecast definition</li><li>Bulk upload definition</li><li>Retention rules</li><li>BVD reports</li></ul><p class="MsoNormal"><span lang="EN-AU" style="text-indent: -0.25in;">Content configuration
is performed by the user logging in to the Content Administration Service
container and executing the </span><span style="text-indent: -0.25in; font-family: &quot;Courier New&quot;;">content-service.sh</span><span style="text-indent: -0.25in;"> </span><span lang="EN-AU" style="text-indent: -0.25in;">CLI.&nbsp;</span>The content
configuration CLI provides the ability to configure a specific content package
or all the content packages available on the system.</p><p class="MsoNormal"><span lang="EN-AU">Out-of-the-box
content (e.g. System Infrastructure reporting, Event reporting) is shipped as
part of the Content Administration Service.&nbsp;
You can extend the out-of-the-box content or create brand new custom
content through an NFS folder based interface, using the same ZIP file format.<o:p></o:p></span></p><p class="MsoNormal"><span lang="EN-AU">When the
same content package (identified by a ZIP file name) is available both within
the Content Administration Service container and outside on the NFS folder
interface, the content ZIP file on the NFS folder is extracted on top of the extracted
content package from within the Content Administration Service, prior to
configuration. This mechanism can be used to extend out-of-the-box content or
configure a brand new content package.<o:p></o:p></span></p><p class="MsoNormal"><span lang="EN-AU">Each content
artifact is discussed in the following sections.<o:p></o:p></span></p><p class="MsoNormal">













































</p><h2><span lang="EN-AU">Steps to create your
custom content<o:p></o:p></span></h2><div><span lang="EN-AU"><img src="https://docs.microfocus.com/mediawiki/images/PN/diag3.PNG"><br></span></div><div><br></div><div><br></div><div><h3><span lang="EN-AU">Step 1: Choose the metrics
to integrate<o:p></o:p></span></h3>

<p class="MsoNormal"><span lang="EN-AU">When using
the Collection Service approach, ensure that the Operation Agent contains the
custom metrics that you want to collect into the COSO Data Lake.&nbsp; You can store custom metrics in the
Operations Agent’s Performance Collection Component in either of these
recommended ways:</span></p><p class="MsoNormal"><ul><li>Use a Perl script to log the metrics.&nbsp; See Using Perl Application Programming Interface for Submitting Custom Data for details.&nbsp; Also see the Easily collect custom metrics using Perl and visualize in OBM blog article for a working example.</li><li>Create a metrics policy.&nbsp; Data sources are database, Perl script, Structured Log File, XML File.</li><li>Use a measurement threshold policy to log metrics defined in the Source tab such as from an External Source, MIB, Program, Perfmon by clicking the “Store in Coda” checkbox for the required source.&nbsp; See Configure Measurement Threshold Policies for details.&nbsp;</li></ul></p>

<h3><span lang="EN-AU">Step 2: Define the COSO
Data Lake configuration<o:p></o:p></span></h3></div><div><img src="https://docs.microfocus.com/mediawiki/images/PN/diag4.PNG"><br></div><div><br></div><div><br></div>